{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "ipaddress = os.environ['ipaddress']\n",
    "dbname = os.environ['dbname']\n",
    "username = os.environ['username']\n",
    "password = os.environ['password']\n",
    "port = os.environ['port']\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    tags = ['ethiopian', 'hawaiian', 'lebanese', 'swedish', 'persian', 'west_african', \n",
    "        'indigenous', 'laotian', 'venezuelan', 'kenyan', 'peruvian', 'latin_american', 'brazilian',\n",
    "        'korean', 'japanese', 'german', 'haitian', 'taiwanese', 'filipino', 'south_african',\n",
    "        'jamaican', 'american', 'bbq', 'chinese', 'french', 'caribbean', 'vietnamese', 'fusion',\n",
    "        'cuban', 'african', 'british', 'thai', 'puerto_rican', 'dominican', 'greek', 'indian',\n",
    "        'seafood', 'middle_eastern', 'mexican', 'italian', 'soul_food']\n",
    "        \n",
    "    y = {}\n",
    "    for t in tags:\n",
    "        y[t] = get_data(t)\n",
    "        y[t][\"tag\"] = t\n",
    "\n",
    "    #Eine Liste aller Dataframes erstellen\n",
    "    listOfDataframes = list(y.keys())\n",
    "    \n",
    "    # Der Loop geht über alle Keys des Dictionary und fügt die Values (Dataframes) zusammen\n",
    "    listOfKeys = []\n",
    "    for i in listOfDataframes:\n",
    "        listOfKeys.append(y[i])\n",
    "    df_total = pd.concat(listOfKeys)\n",
    "    \n",
    "    df = creat_subset(df_total)\n",
    "    \n",
    "    df = clean_data(df)\n",
    "    \n",
    "    # create new df for upload in DB without dictionaries\n",
    "    df_db = df[['name', 'original_video_url','keywords','num_servings','total_time_minutes','yields', 'country',\n",
    "               'id', 'prep_time_minutes', 'description', 'cook_time_minutes', 'nutrition_fiber', 'nutrition_protein',\n",
    "               'nutrition_fat', 'nutrition_calories', 'nutrition_sugar', 'nutrition_carbohydrates',\n",
    "               'user_ratings_count_positive', 'user_ratings_score', 'user_ratings_count_negative',\n",
    "               'total_time_tier_display_tier', 'topics_clean', 'tags_clean', 'credits_clean', 'instructions_clean',\n",
    "               'ingredients']]\n",
    "               \n",
    "    # add cleaned data to DB\n",
    "    # A long string that contains the necessary Postgres login information\n",
    "    postgres_str = f'postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'\n",
    "    \n",
    "    # Create the connection\n",
    "    cnx = create_engine(postgres_str)\n",
    "    \n",
    "    df_db.to_sql('tasty_clean', con=cnx, index=False, if_exists='append')\n",
    "\n",
    "    \n",
    "    # connection for S3\n",
    "    #s3 = boto3.client('s3')\n",
    "    #bucket ='tasty-datalake-bucket'\n",
    "    #csvFile = 'tasty_data.csv'\n",
    "\n",
    "    #csv_buffer = StringIO()\n",
    "    #df.to_csv(csv_buffer)\n",
    "\n",
    "    #s3_resource = boto3.resource('s3')\n",
    "    #s3_resource.Object(bucket, csvFile).put(Body=csv_buffer.getvalue())\n",
    "    \n",
    "    print(\"Data was successfully loaded to DB.\")\n",
    "    \n",
    "\n",
    "def get_data(tag):\n",
    "    \n",
    "    # credentials for Tasty\n",
    "    headers = {\n",
    "    'x-rapidapi-host': \"tasty.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"362fc9c239mshcfe50bd2bfb56f4p1ca4e5jsncbaacdf9bb2a\"\n",
    "    }\n",
    "    \n",
    "    # query to select data from API\n",
    "    url = \"https://tasty.p.rapidapi.com/recipes/list\"\n",
    "\n",
    "    querystring = {\"from\":\"0\",\"size\":\"500\",\"tags\":tag}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    results = response.json()['results']\n",
    "    results = pd.json_normalize(results)\n",
    "    \n",
    "    # create data frame\n",
    "    df_recipes = pd.DataFrame(results)\n",
    "    \n",
    "    return df_recipes\n",
    "\n",
    "    \n",
    "def creat_subset(df):\n",
    "    \n",
    "    df = df[df['instructions'].notna()]\n",
    "    \n",
    "    # create subset\n",
    "    df = df[['name',\n",
    "     'original_video_url',\n",
    "     'topics',\n",
    "     'keywords',\n",
    "     'tags',\n",
    "     'num_servings',\n",
    "     'total_time_minutes',\n",
    "     'yields',\n",
    "     'country',\n",
    "     'tips_and_ratings_enabled',\n",
    "     'aspect_ratio',\n",
    "     'credits',\n",
    "     'sections',\n",
    "     'instructions',\n",
    "     'id',\n",
    "     'prep_time_minutes',\n",
    "     'description',\n",
    "     'cook_time_minutes',\n",
    "     'nutrition.fiber',\n",
    "     'nutrition.protein',\n",
    "     'nutrition.fat',\n",
    "     'nutrition.calories',\n",
    "     'nutrition.sugar',\n",
    "     'nutrition.carbohydrates',\n",
    "     'user_ratings.count_positive',\n",
    "     'user_ratings.score',\n",
    "     'user_ratings.count_negative',\n",
    "     'total_time_tier.display_tier']]\n",
    "     \n",
    "    df = df.rename(columns={'nutrition.fiber': 'nutrition_fiber', 'nutrition.protein': 'nutrition_protein', 'nutrition.fat': 'nutrition_fat', \\\n",
    "        'nutrition.calories': 'nutrition_calories', 'nutrition.sugar': 'nutrition_sugar', 'nutrition.carbohydrates': 'nutrition_carbohydrates', \\\n",
    "        'user_ratings.count_positive': 'user_ratings_count_positive', 'user_ratings.score': 'user_ratings_score', 'user_ratings.count_negative': 'user_ratings_count_negative', \\\n",
    "        'total_time_tier.display_tier': 'total_time_tier_display_tier'})\n",
    "    \n",
    "    return df\n",
    "    \n",
    "# clean data\n",
    "def clean_data(df):\n",
    "    df = df.reset_index()\n",
    "        \n",
    "    df.dropna(subset=['topics'], inplace=True)\n",
    "    df.dropna(subset=['tags'], inplace=True)\n",
    "    df.dropna(subset=['credits'], inplace=True)\n",
    "    df.dropna(subset=['instructions'], inplace=True)\n",
    "    df.dropna(subset=['sections'], inplace=True)\n",
    "        \n",
    "    df = df.drop_duplicates(subset=['name'])\n",
    "        \n",
    "    # Create new list for topics\n",
    "    topics_clean = []\n",
    "        \n",
    "    # For each row in df.topics,\n",
    "    for row in df['topics']:\n",
    "        l = [d['name'] for d in row if 'name' in d]\n",
    "        topics_clean.append(l)\n",
    "        \n",
    "    # Assign clean topics to df\n",
    "    df['topics_clean'] = topics_clean\n",
    "        \n",
    "    # Create new list for tags\n",
    "    tags_clean = []\n",
    "        \n",
    "    # For each row in df.topics,\n",
    "    for row in df['tags']:\n",
    "        l = [d['name'] for d in row if 'name' in d]\n",
    "        tags_clean.append(l)\n",
    "        \n",
    "    # Assign clean tags to df\n",
    "    df['tags_clean'] = tags_clean\n",
    "        \n",
    "    # Create new list for credits\n",
    "    credits_clean = []\n",
    "        \n",
    "    # For each row in df.topics,\n",
    "    for row in df['credits']:\n",
    "        l = [d['type'] for d in row if 'type' in d]\n",
    "        credits_clean.append(l)\n",
    "        \n",
    "    # Assign clean credits to df\n",
    "    df['credits_clean'] = credits_clean\n",
    "        \n",
    "    # clean ingredients\n",
    "    d = df['sections']\n",
    "    ing_list = []\n",
    "    for s in d:\n",
    "        for jj in s:\n",
    "            lst4 = []\n",
    "            for ee in jj['components']:\n",
    "                lst4.append(ee['ingredient']['name'])\n",
    "        ing_list.append(lst4)\n",
    "    df['ingredients'] = ing_list\n",
    "        \n",
    "    # Create a variable\n",
    "    instructions_clean = []\n",
    "        \n",
    "    # For each row in df.topics,\n",
    "    for row in df['instructions']:\n",
    "        l = [d['display_text'] for d in row if 'display_text' in d]\n",
    "        instructions_clean.append(l)\n",
    "        \n",
    "    # Assign clean topics to df\n",
    "    df['instructions_clean'] = instructions_clean\n",
    "        \n",
    "    # Convert set to list\n",
    "    df['credits_clean'] = df['credits_clean'].apply(lambda x: list(x))\n",
    "        \n",
    "    # change name to lowercase\n",
    "    df['name'] = df['name'].str.lower()\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
